---
title: "Weight Maps"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Weight Maps}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(dplyr)
library(data.table)
library(RNetCDF)
library(sf)
library(ncmeta)
library(intersectr)
devtools::load_all()

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

The first step in creating a zonal 


### Option 1: Intersectr: 

```{r}
option1 = function(file, geom, ID){
  nc_coord_vars <- nc_coord_var(file)
  variable_name <- "potential_evapotranspiration"
  nc_coord_vars <- filter(nc_coord_vars, variable == variable_name)
  
  nc       <- open.nc(file)
  X_coords <- var.get.nc(nc, nc_coord_vars$X, unpack = TRUE)
  Y_coords <- var.get.nc(nc, nc_coord_vars$Y, unpack = TRUE)
  
  nc_prj <- nc_gm_to_prj(nc_grid_mapping_atts(file))
    
  cell_geometry = create_cell_geometry(X_coords = X_coords,
                         Y_coords = Y_coords,
                         prj = nc_prj,
                         geom = geom, 
                         buffer_dist = 0.1, # Degrees
                         regularize = TRUE)
    
  data_source_cells <- st_sf(dplyr::select(cell_geometry, grid_ids))
  target_polygons   <- st_sf(dplyr::select(geom, !!ID))
  st_agr(data_source_cells) <- "constant"
  st_agr(target_polygons)   <- "constant"
    
  calculate_area_intersection_weights(
      data_source_cells,
      target_polygons, allow_lonlat = TRUE)
}

```

### Option 2: zonal 1: 

```{r}
option2 = function(file, geom, ID){
  build_grid(file, geom) %>% 
    build_weights(geom, ID)
}
```

### Option 3: zonal 2: 

```{r}
option3 = function(file, geom, ID){
  weighting_grid(file, geom, ID = "comid", progress = FALSE)
}

```

# HUC01

 - Large Area, Lots of aggregation units

```{r}
file = '/Users/mjohnson/Downloads/pet_1979.nc'

geom <- read_sf('/Users/mjohnson/github/hydrofabric/workflow/nhd_workflows/cache/ngen_01a-4.gpkg', "catchments") %>% 
  st_make_valid()
```

The gridded data and aggregate units we are working with can be seen below:

```{r data-grid}
file = '/Users/mjohnson/Downloads/pet_1979.nc'
(meta = nc_dims(file))
```

The grid we are working with holds daily PET values for CONUS for the year 1979. It has:
 - `r prettyNum(filter(meta, name == 'lon')$length, big.mark = ",")` X_cells
 - `r prettyNum(filter(meta, name == 'lat')$length, big.mark = ",")` Y_cells 
 - `r prettyNum(filter(meta, name == 'day')$length, big.mark = ",")` time slices 

for a total of `r prettyNum(prod(meta$length), big.mark = ",")` values.

```{r data-geom}
geom <- read_sf('/Users/mjohnson/github/hydrofabric/workflow/nhd_workflows/cache/ngen_01a-4.gpkg', "catchments") %>% 
  st_make_valid()

glimpse(geom)
```
  
In total we have `r prettyNum(nrow(geom), big.mark = ",")` aggregation units to summarize over the `r filter(meta, name == 'day')$length` time steps.


```{r}
bnch <- bench::mark(
  iterations = 1, check = FALSE,
  intersectr = option1(file, geom, "comid"),
  zonal1     = option2(file, geom, "comid"),
  zonal3     = option3(file, geom, "comid")
)
```

```{r, echo = FALSE}
bnch %>%
  dplyr::select(expression, median, mem_alloc) %>%
  mutate(expression = names(expression),
         median_rel = unclass(median/min(median)),
         mem_rel = unclass(mem_alloc/min(mem_alloc))) %>% 
  formattable::formattable()
```

# Colorado

 - Large Area with a few large aggregation units

```{r}
colorado  = AOI::aoi_get(state = 'CO', county = "all")
```


```{r}
bnch2 <- bench::mark(
  iterations = 1, check = FALSE,
  intersectr = option1(file, colorado, "name"),
  zonal1     = option2(file, colorado, "name"),
  zonal3     = option3(file, colorado, "name")
)
```

```{r, echo = FALSE}
bnch2 %>%
  dplyr::select(expression, median, mem_alloc) %>%
  mutate(expression = names(expression),
         median_rel = unclass(median/min(median)),
         mem_rel = unclass(mem_alloc/min(mem_alloc))) %>% 
  formattable::formattable()
```
